{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack overflow tag classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing packages ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer,IndexToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/shreyas/GeminiData/seed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_Id', '_PostTypeId', '_CreationDate', '_Score', '_ViewCount', '_Body',\n",
       "       '_OwnerUserId', '_LastActivityDate', '_Title', '_Tags', '_AnswerCount',\n",
       "       '_CommentCount', '_FavoriteCount', '_LastEditorUserId',\n",
       "       '_AcceptedAnswerId', '_LastEditDate', '_ParentId', '_Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['_Body','_Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_Id', '_PostTypeId', '_CreationDate', '_Score', '_ViewCount', '_Body',\n",
       "       '_OwnerUserId', '_LastActivityDate', '_Title', '_Tags', '_AnswerCount',\n",
       "       '_CommentCount', '_FavoriteCount', '_LastEditorUserId',\n",
       "       '_AcceptedAnswerId', '_LastEditDate', '_ParentId', 'Unnamed: 17',\n",
       "       'Unnamed: 18', 'Unnamed: 19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = pd.read_csv(\"/home/shreyas/GeminiData/input_data.csv\")\n",
    "testdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=testdata[['_Body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_Body</th>\n",
       "      <th>_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;Are questions related to &lt;a href=\"http://ww...</td>\n",
       "      <td>bricks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;What is a good tag for purchasing/acquiring...</td>\n",
       "      <td>bricks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;I've asked one, so &lt;a href=\"https://bricks....</td>\n",
       "      <td>bricks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;Lego Mindstorms allows one to write embedde...</td>\n",
       "      <td>bricks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;I suspect that Mindstorms by itself is not ...</td>\n",
       "      <td>bricks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               _Body _Category\n",
       "0  <p>Are questions related to <a href=\"http://ww...    bricks\n",
       "1  <p>What is a good tag for purchasing/acquiring...    bricks\n",
       "2  <p>I've asked one, so <a href=\"https://bricks....    bricks\n",
       "3  <p>Lego Mindstorms allows one to write embedde...    bricks\n",
       "4  <p>I suspect that Mindstorms by itself is not ...    bricks"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;Are questions related to &lt;a href=\"http://ww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;What is a good tag for purchasing/acquiring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;I've asked one, so &lt;a href=\"https://bricks....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;Lego Mindstorms allows one to write embedde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;I suspect that Mindstorms by itself is not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               _Body\n",
       "0  <p>Are questions related to <a href=\"http://ww...\n",
       "1  <p>What is a good tag for purchasing/acquiring...\n",
       "2  <p>I've asked one, so <a href=\"https://bricks....\n",
       "3  <p>Lego Mindstorms allows one to write embedde...\n",
       "4  <p>I suspect that Mindstorms by itself is not ..."
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testdata contains missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['_Category'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_Body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_Category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3dprinting</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agur</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agur.meta</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arabic</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arabic.meta</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avp</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beer</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioinformatics</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bricks</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                _Body\n",
       "_Category            \n",
       "3dprinting         10\n",
       "agur               10\n",
       "agur.meta          10\n",
       "ai                  9\n",
       "arabic             10\n",
       "arabic.meta        11\n",
       "avp                10\n",
       "beer                9\n",
       "bioinformatics     10\n",
       "bricks             10"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['_Category']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object oriented flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a parent class __categoryPrediction__ which performs data reading, cleaning and transformation to make them suitable for classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "class categoryPrediction:\n",
    "\n",
    "\n",
    "    # Method to read training data and extracting only useful columns (body and category) from it.\n",
    "    # This method takes one argument, filename and returns spark dataframe.\n",
    "    \n",
    "    def readTrain(self,file):\n",
    "        \n",
    "        #Reading file as pandas dataframe.\n",
    "        data = pd.read_csv(file)\n",
    "        data=data[['_Body','_Category']]\n",
    "        \n",
    "        # This function is defined later in the same class.\n",
    "        trainDf=self.readContent(data)\n",
    "        \n",
    "        # Converting pandas dataframe to spark dataframe.\n",
    "        spark_df = sqlContext.createDataFrame(data[['body','_Category']])\n",
    "        return spark_df\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "   # As testdata doesn't have labels, the same function can't be used for test file. So another function is\n",
    "        # defined which extracts only body column. This function also returns spark dataframe.\n",
    "    \n",
    "    def readTest(self,file):\n",
    "        testdata = pd.read_csv(file)\n",
    "        testdata=testdata[['_Body']]\n",
    "        \n",
    "        # Testdata has some values missing. The rows which doesn't have data are removed.\n",
    "        testdata=testdata.dropna()\n",
    "        trainDf=self.readContent(testdata)\n",
    "        spark_df_test = sqlContext.createDataFrame(testdata[['body']])\n",
    "        return spark_df_test\n",
    "\n",
    "    # This function is referenced in the previous functions. The column '_body' contains data in the html tag \n",
    "        # format. This function extracts the text data from the _body column. This function returns cleaned dataframe.\n",
    "        \n",
    "    def readContent(self,data):\n",
    "        for j in range(data.shape[0]):\n",
    "            soup=BS(data._Body.iloc[j])\n",
    "            s=''\n",
    "            \n",
    "            # The text data is contained in the paragraphs only. So the text inside that tag is extracted using\n",
    "            # Beautifulsoup library. There are multiple paragraph tags. The text from all of them is Concatenated.\n",
    "                \n",
    "            for i in range(len(soup.findAll(lambda tag: tag.name == 'p' ))):\n",
    "                s+=(soup.find_all('p')[i].get_text())+' '\n",
    "            s=s[:-1] \n",
    "            data.loc[data.index[j], 'body'] = s\n",
    "        return data\n",
    "    \n",
    "    # This method is used to clean the data using spark. This function returns vectorized features.\n",
    "    # This method can be used for both training and test data.\n",
    "    \n",
    "    def clean(self,df):\n",
    "        \n",
    "        # This function keeps only words and tokenize them. Other contents like symbols, digits are removed.\n",
    "        \n",
    "        regexTokenizer = RegexTokenizer(inputCol=\"body\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "        regexTokenized = regexTokenizer.transform(df)\n",
    "        \n",
    "        # This function removes stop words which are irrelevant for classification.\n",
    "        \n",
    "        remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "        sw=remover.transform(regexTokenized)\n",
    "        \n",
    "        # TF-IDF is used to convert tokenized words into the integer features.\n",
    "        \n",
    "        hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "        featurizedData = hashingTF.transform(sw)\n",
    "        idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "        idfModel = idf.fit(featurizedData)\n",
    "        rescaledData = idfModel.transform(featurizedData)\n",
    "        return rescaledData\n",
    "        \n",
    "    \n",
    "    # This method is used to convert string labels into integer labels. \n",
    "    \n",
    "    def categoryToLabel(self,df):\n",
    "        indexer = StringIndexer(inputCol=\"_Category\", outputCol=\"categoryIndex\")\n",
    "        train = indexer.fit(df).transform(df)\n",
    "        return train\n",
    "\n",
    "    # This method is used to convert integer labels created using previous method back to the string category(Tag)\n",
    "    \n",
    "    def labelToCategory(self,df):\n",
    "        labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",labels=indexer.labels)\n",
    "        output=labelConverter.transform(df)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "    # This method is used to split labeled data into training and evaluation (validation) sets.\n",
    "    # 70% of the total data is used for training and 30% is used for validation.\n",
    "    # This function returns both the dataframes created.\n",
    "    \n",
    "    def split(self,df):\n",
    "        (train, ev) = df.randomSplit([0.7, 0.3])\n",
    "        return (train, ev)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to understand what exactly is happening after every operation performed on the training data (Following steps are not the part of class. We are just holding object oriented flow to understand the operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                body|_Category|\n",
      "+--------------------+---------+\n",
      "|Are questions rel...|   bricks|\n",
      "|What is a good ta...|   bricks|\n",
      "|I've asked one, s...|   bricks|\n",
      "|Lego Mindstorms a...|   bricks|\n",
      "|I suspect that Mi...|   bricks|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = sqlContext.createDataFrame(data[['body','_Category']])\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                body|\n",
      "+--------------------+\n",
      "|Are questions rel...|\n",
      "|What is a good ta...|\n",
      "|I've asked one, s...|\n",
      "|Lego Mindstorms a...|\n",
      "|I suspect that Mi...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_test = sqlContext.createDataFrame(testdata[['body']])\n",
    "spark_df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                body|_Category|               words|\n",
      "+--------------------+---------+--------------------+\n",
      "|Are questions rel...|   bricks|[are, questions, ...|\n",
      "|What is a good ta...|   bricks|[what, is, a, goo...|\n",
      "+--------------------+---------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"body\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "regexTokenized = regexTokenizer.transform(spark_df)\n",
    "regexTokenized_test = regexTokenizer.transform(spark_df_test)\n",
    "regexTokenized.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+\n",
      "|                body|_Category|               words|            filtered|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "|Are questions rel...|   bricks|[are, questions, ...|[questions, relat...|\n",
      "|What is a good ta...|   bricks|[what, is, a, goo...|[good, tag, purch...|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "sw=remover.transform(regexTokenized)\n",
    "sw_test=remover.transform(regexTokenized_test)\n",
    "sw.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF - Term frequency - inverse document frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF - number of times term is appearing in document <br>\n",
    "IDF - log of inverse fraction of documents having term t with total number of document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                body|_Category|               words|            filtered|         rawFeatures|            features|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Are questions rel...|   bricks|[are, questions, ...|[questions, relat...|(30,[1,2,4,7,14,2...|(30,[1,2,4,7,14,2...|\n",
      "|What is a good ta...|   bricks|[what, is, a, goo...|[good, tag, purch...|(30,[1,7,8,9,13,1...|(30,[1,7,8,9,13,1...|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=30)\n",
    "featurizedData = hashingTF.transform(sw)\n",
    "featurizedData_test = hashingTF.transform(sw_test)\n",
    "\n",
    "# alternatively, CountVectorizer can also be used to get term frequency vectors\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "idfModel_test = idf.fit(featurizedData_test)\n",
    "\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData_test = idfModel_test.transform(featurizedData_test)\n",
    "\n",
    "rescaledData.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other options for feature engineering: <br>\n",
    "    1) n-grams <br>\n",
    "    2) bag of words <br>\n",
    "    3) Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|_Category|            features|\n",
      "+---------+--------------------+\n",
      "|   bricks|(20,[1,2,4,7,10,1...|\n",
      "|   bricks|(20,[3,5,7,8,9,11...|\n",
      "+---------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final=rescaledData.select(\"_Category\",\"features\")\n",
    "final.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"_Category\", outputCol=\"categoryIndex\").fit(final)\n",
    "train = indexer.transform(final)\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=indexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-------------+\n",
      "|_Category|            features|categoryIndex|\n",
      "+---------+--------------------+-------------+\n",
      "|   bricks|(20,[1,2,4,7,10,1...|          6.0|\n",
      "|   bricks|(20,[3,5,7,8,9,11...|          6.0|\n",
      "|   bricks|(20,[2,4,7,8,10,1...|          6.0|\n",
      "|   bricks|(20,[0,1,3,4,7,9,...|          6.0|\n",
      "|   bricks|(20,[0,1,2,4,5,10...|          6.0|\n",
      "+---------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let's continue with the object oriented flow where we had left it, by defining children classes for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble method - Uses multiple decision trees. Makes decision by majority voting (Mode, Average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a child class __randomForest__ which trains a classification model, evaluate performance of model on validation set and predict labels for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "class randomForest(categoryPrediction):\n",
    "    \n",
    "    # This method is used to train classification model using random forest algorithm.\n",
    "    \n",
    "    def training(self,df):\n",
    "        rf = RandomForestClassifier(labelCol=\"categoryIndex\", featuresCol=\"features\", numTrees=10)\n",
    "        #pipelinerf = Pipeline(stages=[rf, labelConverter])\n",
    "        rfmodel = rf.fit(df)\n",
    "        return rfmodel\n",
    "\n",
    "    # This method is used to evaluate validation set created using method in the parent class. This method takes\n",
    "    # trained model, validation set as the inputs and returns accuracy ranging from 0 to 1.\n",
    "    \n",
    "    def evaluation(self,df,rfmodel):\n",
    "        predictions1 = rfmodel.transform(df)\n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "        accuracy = evaluator.evaluate(predictions1)\n",
    "        return accuracy\n",
    "        \n",
    "    # This method is used to predict tags based on trained random forest model. It takes trained model and test\n",
    "    # data as the argument and returns pandas dataframe having single column which contains predicted tags.\n",
    "    \n",
    "    def prediction(self,df,rfmodel):\n",
    "        rfPred=rfmodel.transform(df)\n",
    "        rfPred=categoryPrediction.labelToCategory(self,rfPred)\n",
    "        rfres=(rfPred.select('predictedLabel').toPandas())\n",
    "        rfres.rename(columns={'predictedLabel':'rf_prediction'}, inplace=True)\n",
    "        return rfres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Other hyperparameters:__ <br>\n",
    "Maxdepth <br>\n",
    "Maxbins "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumes that all the features are independant and are having equal significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a child class __naiveBayes__ which trains a classification model using Naive Bayes algorithm, evaluate performance of model on validation set and predict labels for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naiveBayes(categoryPrediction):\n",
    "    \n",
    "    def training(self,df):\n",
    "        nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\",labelCol=\"categoryIndex\")\n",
    "        nbmodel = nb.fit(df)\n",
    "        return nbmodel\n",
    "\n",
    "    def evaluation(self,df,nbmodel):\n",
    "        predictions2 = nbmodel.transform(df)\n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "        accuracy = evaluator.evaluate(predictions2)\n",
    "        return accuracy\n",
    "        \n",
    "    def prediction(self,df,nbmodel):\n",
    "        nbPred=nbmodel.transform(df)\n",
    "        nbPred=categoryPrediction.labelToCategory(self,nbPred)\n",
    "        nbres=(nbPred.select('predictedLabel').toPandas())\n",
    "        nbres.rename(columns={'predictedLabel':'nb_prediction'}, inplace=True)\n",
    "        return nbres\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Other model types:__ <br>\n",
    "    Gaussian model - Continuous data <br>\n",
    "    Bernoulli's model - Binary features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Smoothing__:\n",
    "Some Probabilities might be 0, So Laplace's smoothing is used. The number is added to the total count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gives probability of every class. The class having maximum probability is the selected class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a child class __logisticRegression__ which trains a classification model using logistic regression algorithm, evaluate performance of model on validation set and predict labels for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticRegression(categoryPrediction):\n",
    "    \n",
    "    def training(self,df):\n",
    "        lr = LogisticRegression(labelCol=\"categoryIndex\", featuresCol=\"features\", maxIter=20)\n",
    "        #pipelinerf = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "        lrmodel = lr.fit(df)\n",
    "        return lrmodel\n",
    "\n",
    "    def evaluation(self,df,lrmodel):\n",
    "        predictions3 = lrmodel.transform(df)\n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "        accuracy = evaluator.evaluate(predictions3)\n",
    "        return accuracy\n",
    "        \n",
    "    def prediction(self,df,lrmodel):\n",
    "        lrPred=lrmodel.transform(df)\n",
    "        lrPred=categoryPrediction.labelToCategory(self,lrPred)\n",
    "        lrres=(lrPred.select('predictedLabel').toPandas())\n",
    "        lrres.rename(columns={'predictedLabel':'lr_prediction'}, inplace=True)\n",
    "        return lrres\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Hyperparameter tuning - Gridsearch\n",
    "Enables to vary parameters and best parameters are suggested based on cross-validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating objects for children and parent classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj=categoryPrediction()\n",
    "rfobj=randomForest()\n",
    "nbobj=naiveBayes()\n",
    "lrobj=logisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data reading, cleaning and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=obj.readTrain(\"/home/shreyas/GeminiData/seed.csv\")\n",
    "testSet=obj.readTest(\"/home/shreyas/GeminiData/input_data.csv\")\n",
    "cleanTrain=obj.clean(train)\n",
    "cleantestSet=obj.clean(testSet)\n",
    "indexedTrain=obj.categoryToLabel(cleanTrain)\n",
    "trainSet,evalSet=obj.split(indexedTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression train set Accuracy:  61.76470588235294 %\n",
      "Logistic regression Accuracy:  19.35483870967742 %\n"
     ]
    }
   ],
   "source": [
    "lrmodel=lrobj.training(trainSet)\n",
    "lrAcc=lrobj.evaluation(evalSet,lrmodel)\n",
    "lrres=lrobj.prediction(cleantestSet,lrmodel)\n",
    "lrAccTrain=nbobj.evaluation(trainSet,nbmodel)\n",
    "print('Logistic regression train set Accuracy: ',lrAccTrain*100,'%')\n",
    "print('Logistic regression Accuracy: ',lrAcc*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes train set Accuracy:  61.76470588235294 %\n",
      "Naive Bayes validation set Accuracy:  12.903225806451612 %\n"
     ]
    }
   ],
   "source": [
    "nbmodel=nbobj.training(trainSet)\n",
    "nbAcc=nbobj.evaluation(evalSet,nbmodel)\n",
    "nbres=nbobj.prediction(cleantestSet,nbmodel)\n",
    "nbAccTrain=nbobj.evaluation(trainSet,nbmodel)\n",
    "print('Naive Bayes train set Accuracy: ',nbAccTrain*100,'%')\n",
    "print('Naive Bayes validation set Accuracy: ',nbAcc*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest train set Accuracy:  89.70588235294117 %\n",
      "Random Forest Accuracy:  25.806451612903224 %\n"
     ]
    }
   ],
   "source": [
    "rfmodel=rfobj.training(trainSet)\n",
    "rfAcc=rfobj.evaluation(evalSet,rfmodel)\n",
    "rfres=rfobj.prediction(cleantestSet,rfmodel)\n",
    "rfAccTrain=nbobj.evaluation(trainSet,rfmodel)\n",
    "print('Random forest train set Accuracy: ',rfAccTrain*100,'%')\n",
    "print('Random Forest Accuracy: ',rfAcc*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the models are over-fitted and performing very bad due to insufficient data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In RF, trees are splitted in random subset of features which avoids overfitting and also weak features are improved by multiple decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Other metrics to evaluate classification algorithms:__\n",
    "1) Precision <br>\n",
    "2) Recall <br>\n",
    "3) Confussion matrix <br>\n",
    "4) F-1 Score <br>\n",
    "5) Roc Curve <br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a pandas dataframe which contains text data and predicted tags using all the classification mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=testSet.toPandas()\n",
    "pred=pd.concat([question,rfres,nbres,lrres],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing dataframe into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('Stack Overflow Tag Classification.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
